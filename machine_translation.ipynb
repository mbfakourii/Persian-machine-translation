{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"machine_translation","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb","timestamp":1623327735515}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xQkkdXcZvYP0"},"source":["import pathlib\n","import random\n","import string\n","import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.models import Sequential, load_model\n","from keras.layers.experimental.preprocessing import TextVectorization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSkWvRk1vYP0"},"source":["**Downloading the data**\n","\n","[Anki](https://www.manythings.org/anki/)"]},{"cell_type":"code","metadata":{"id":"swP2IW2GvYP1"},"source":["text_file1 = keras.utils.get_file(\n","    fname=\"pes-eng.zip\",\n","    origin=\"https://dl.dropboxusercontent.com/s/b7b1xr2tyexhn89/pes-eng.zip\",\n","    extract=True,\n",")\n","text_file1 = pathlib.Path(text_file1).parent  / \"pes.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZkMLZV6vYP2"},"source":["with open(text_file1) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","\n","text_persian = []\n","len(lines)\n","for line in lines:\n","  eng = line.split(\"\\t\")[0]\n","  pes = line.split(\"\\t\")[1]\n","  pes = \"[start] \" + pes + \" [end]\"\n","  text_persian.append((eng, pes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RIO9Xo4yDQyZ"},"source":["**[MIZAN: A Large Persian-English Parallel Corpus](https://github.com/omidkashefi/Mizan/)**\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmF96dIr4JfH","executionInfo":{"status":"ok","timestamp":1623398110957,"user_tz":-270,"elapsed":5539,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"dd0de3a9-75da-4b31-9f3f-61bcd9adef26"},"source":["text_file2 = keras.utils.get_file(\n","    fname=\"mizan.zip\",\n","    origin=\"https://github.com/omidkashefi/Mizan/blob/master/mizan.zip?raw=true\",\n","    extract=True,\n",")\n","text_file2_pes = pathlib.Path(text_file2).parent / \"mizan\" / \"mizan_fa.txt\"\n","text_file2_en = pathlib.Path(text_file2).parent / \"mizan\" / \"mizan_en.txt\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/omidkashefi/Mizan/blob/master/mizan.zip?raw=true\n","57729024/57728332 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxT0Z9D94w6u"},"source":["with open(text_file2_en) as f:\n","  lines_en = f.read().split(\"\\n\")[:-1]\n","\n","with open(text_file2_pes) as f:\n","  lines_pes = f.read().split(\"\\n\")[:-1]\n","\n","for line in range(len(lines_en)):\n","  eng = lines_en[line]\n","  pes = lines_pes[line]\n","  text_persian.append((eng, pes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEkp1h9QvYP4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623406135668,"user_tz":-270,"elapsed":431,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"1b5fe9d5-a66e-4449-aa7f-df53a93d020a"},"source":["for _ in range(5):\n","    print(random.choice(text_persian))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('He came to see me.', '[start] وی آمد تا من را ببیند. [end]')\n","(\"I don't even know him.\", '[start] من حتی او را نمی شناسم. [end]')\n","('Where can we find the truth?', '[start] حقیقت را در کجا می توانیم بیابیم؟ [end]')\n","('Why do you suspect me?', '[start] چرا به من مظنون هستید؟ [end]')\n","('Tom wants to change the world.', '[start] تام می خواهد جهان را تغییر دهد. [end]')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"npEbE_u1vYP5"},"source":["Now, let's split the sentence persian into a training set, a validation set,\n","and a test set."]},{"cell_type":"code","metadata":{"id":"cZmONgvovYP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623406139990,"user_tz":-270,"elapsed":427,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"9c1f664d-624b-4594-be69-dcfef16dc29a"},"source":["random.shuffle(text_persian)\n","num_val_samples = int(0.15 * len(text_persian))\n","num_train_samples = len(text_persian) - 2 * num_val_samples\n","train_persian = text_persian[:num_train_samples]\n","val_persian = text_persian[num_train_samples : num_train_samples + num_val_samples]\n","test_persian = text_persian[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_persian)} total persian\")\n","print(f\"{len(train_persian)} training persian\")\n","print(f\"{len(val_persian)} validation persian\")\n","print(f\"{len(test_persian)} test persian\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2521 total persian\n","1765 training persian\n","378 validation persian\n","378 test persian\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m4d_wYx8vYP6"},"source":["**Preprocessing And Vectorizing the text data**\n"]},{"cell_type":"code","metadata":{"id":"qweN3CSjvYP7"},"source":["strip_chars = string.punctuation + \"؟\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","vocab_size = 129500\n","sequence_length = 20\n","batch_size = 64\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","# TextVectorization = This layer has basic options for managing text in a Keras model\n","eng_vectorization = TextVectorization(\n","    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",")\n","pes_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_eng_texts = [pair[0] for pair in train_persian]\n","train_pes_texts = [pair[1] for pair in train_persian]\n","eng_vectorization.adapt(train_eng_texts)\n","pes_vectorization.adapt(train_pes_texts)\n","\n","def format_dataset(eng, pes):\n","    eng = eng_vectorization(eng)\n","    pes = pes_vectorization(pes)\n","    return ({\"encoder_inputs\": eng, \"decoder_inputs\": pes[:, :-1],}, pes[:, 1:])\n","\n","\n","def make_dataset(persian):\n","    eng_texts, pes_texts = zip(*persian)\n","    eng_texts = list(eng_texts)\n","    pes_texts = list(pes_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, pes_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_persian)\n","val_ds = make_dataset(val_persian)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azPNe7rXvYP-"},"source":["**sequence shapes**"]},{"cell_type":"code","metadata":{"id":"16YV9Gc6vYP_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623406149494,"user_tz":-270,"elapsed":6,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"003a628f-e637-4ddc-832a-2844aa183371"},"source":["for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tws6GX3pvYP_"},"source":["**Building the model**"]},{"cell_type":"code","metadata":{"id":"l5fDlMDQvYQA"},"source":["\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n"," \n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","# To make the model aware of word order\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super(PositionalEmbedding, self).__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super(TransformerDecoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    # A key detail that makes this possible is causal masking \n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSrN6jpVl9ll"},"source":["**Assemble Model**"]},{"cell_type":"code","metadata":{"id":"YcjqwlYHvYQD"},"source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","\n","# --------- > encoder\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","\n","# Model groups layers into an object with training and inference features.\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","# --------- > decoder\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3t85iovzvYQE"},"source":["**Training our model**"]},{"cell_type":"code","metadata":{"id":"QfNw2Co6vYQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623407908475,"user_tz":-270,"elapsed":1658546,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"99dae246-8d46-4820-9f94-284f6b1bfa23"},"source":["epochs = 100\n"," \n","transformer.summary()\n","transformer.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","\n","transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_inputs (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","positional_embedding (Positiona (None, None, 256)    33157120    encoder_inputs[0][0]             \n","__________________________________________________________________________________________________\n","decoder_inputs (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","transformer_encoder (Transforme (None, None, 256)    3155456     positional_embedding[0][0]       \n","__________________________________________________________________________________________________\n","model_1 (Functional)            (None, None, 129500) 71698140    decoder_inputs[0][0]             \n","                                                                 transformer_encoder[0][0]        \n","==================================================================================================\n","Total params: 108,010,716\n","Trainable params: 108,010,716\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 16s 481ms/step - loss: 1.4734 - accuracy: 0.4555 - val_loss: 2.4025 - val_accuracy: 0.3503\n","Epoch 2/100\n","28/28 [==============================] - 13s 453ms/step - loss: 1.1492 - accuracy: 0.5594 - val_loss: 2.5365 - val_accuracy: 0.3515\n","Epoch 3/100\n","28/28 [==============================] - 13s 451ms/step - loss: 0.8949 - accuracy: 0.6420 - val_loss: 2.4462 - val_accuracy: 0.3411\n","Epoch 4/100\n","28/28 [==============================] - 13s 454ms/step - loss: 0.7302 - accuracy: 0.7029 - val_loss: 2.4804 - val_accuracy: 0.3577\n","Epoch 5/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.5751 - accuracy: 0.7699 - val_loss: 2.5724 - val_accuracy: 0.3628\n","Epoch 6/100\n","28/28 [==============================] - 13s 451ms/step - loss: 0.4375 - accuracy: 0.8294 - val_loss: 2.5164 - val_accuracy: 0.3443\n","Epoch 7/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.3464 - accuracy: 0.8730 - val_loss: 2.6345 - val_accuracy: 0.3551\n","Epoch 8/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.2739 - accuracy: 0.9006 - val_loss: 2.6136 - val_accuracy: 0.3503\n","Epoch 9/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.2140 - accuracy: 0.9284 - val_loss: 2.6403 - val_accuracy: 0.3676\n","Epoch 10/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.1788 - accuracy: 0.9415 - val_loss: 2.6129 - val_accuracy: 0.3571\n","Epoch 11/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.1452 - accuracy: 0.9563 - val_loss: 2.6997 - val_accuracy: 0.3598\n","Epoch 12/100\n","28/28 [==============================] - 13s 454ms/step - loss: 0.1324 - accuracy: 0.9588 - val_loss: 2.6344 - val_accuracy: 0.3625\n","Epoch 13/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.1142 - accuracy: 0.9640 - val_loss: 2.6726 - val_accuracy: 0.3598\n","Epoch 14/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 2.7962 - val_accuracy: 0.3610\n","Epoch 15/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.0948 - accuracy: 0.9697 - val_loss: 2.6795 - val_accuracy: 0.3601\n","Epoch 16/100\n","28/28 [==============================] - 13s 455ms/step - loss: 0.1097 - accuracy: 0.9632 - val_loss: 2.7000 - val_accuracy: 0.3604\n","Epoch 17/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0872 - accuracy: 0.9707 - val_loss: 2.7241 - val_accuracy: 0.3551\n","Epoch 18/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0836 - accuracy: 0.9740 - val_loss: 2.7461 - val_accuracy: 0.3607\n","Epoch 19/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0805 - accuracy: 0.9749 - val_loss: 2.7280 - val_accuracy: 0.3649\n","Epoch 20/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0796 - accuracy: 0.9736 - val_loss: 2.7030 - val_accuracy: 0.3598\n","Epoch 21/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0698 - accuracy: 0.9791 - val_loss: 2.7335 - val_accuracy: 0.3616\n","Epoch 22/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 2.7290 - val_accuracy: 0.3667\n","Epoch 23/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 2.7055 - val_accuracy: 0.3551\n","Epoch 24/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 2.7036 - val_accuracy: 0.3717\n","Epoch 25/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 2.7141 - val_accuracy: 0.3667\n","Epoch 26/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0722 - accuracy: 0.9764 - val_loss: 2.7322 - val_accuracy: 0.3670\n","Epoch 27/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.0547 - accuracy: 0.9809 - val_loss: 2.6895 - val_accuracy: 0.3625\n","Epoch 28/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0617 - accuracy: 0.9800 - val_loss: 2.7383 - val_accuracy: 0.3619\n","Epoch 29/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 2.7653 - val_accuracy: 0.3619\n","Epoch 30/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 2.7377 - val_accuracy: 0.3533\n","Epoch 31/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 2.7309 - val_accuracy: 0.3577\n","Epoch 32/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0542 - accuracy: 0.9819 - val_loss: 2.7373 - val_accuracy: 0.3548\n","Epoch 33/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 2.7361 - val_accuracy: 0.3628\n","Epoch 34/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0507 - accuracy: 0.9835 - val_loss: 2.6912 - val_accuracy: 0.3530\n","Epoch 35/100\n","28/28 [==============================] - 13s 454ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 2.7027 - val_accuracy: 0.3649\n","Epoch 36/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 2.7137 - val_accuracy: 0.3607\n","Epoch 37/100\n","28/28 [==============================] - 13s 455ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 2.7415 - val_accuracy: 0.3640\n","Epoch 38/100\n","28/28 [==============================] - 13s 453ms/step - loss: 0.0515 - accuracy: 0.9838 - val_loss: 2.7393 - val_accuracy: 0.3527\n","Epoch 39/100\n","28/28 [==============================] - 13s 454ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 2.7209 - val_accuracy: 0.3574\n","Epoch 40/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 2.7428 - val_accuracy: 0.3571\n","Epoch 41/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0444 - accuracy: 0.9846 - val_loss: 2.7175 - val_accuracy: 0.3545\n","Epoch 42/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 2.7961 - val_accuracy: 0.3548\n","Epoch 43/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0465 - accuracy: 0.9860 - val_loss: 2.7494 - val_accuracy: 0.3455\n","Epoch 44/100\n","28/28 [==============================] - 13s 456ms/step - loss: 0.0604 - accuracy: 0.9786 - val_loss: 2.7376 - val_accuracy: 0.3640\n","Epoch 45/100\n","28/28 [==============================] - 13s 455ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 2.7763 - val_accuracy: 0.3583\n","Epoch 46/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 2.7513 - val_accuracy: 0.3574\n","Epoch 47/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 2.7545 - val_accuracy: 0.3595\n","Epoch 48/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0440 - accuracy: 0.9843 - val_loss: 2.8127 - val_accuracy: 0.3598\n","Epoch 49/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0414 - accuracy: 0.9854 - val_loss: 2.8133 - val_accuracy: 0.3571\n","Epoch 50/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0455 - accuracy: 0.9841 - val_loss: 2.7880 - val_accuracy: 0.3500\n","Epoch 51/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 2.8066 - val_accuracy: 0.3548\n","Epoch 52/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 2.8509 - val_accuracy: 0.3521\n","Epoch 53/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 2.7976 - val_accuracy: 0.3545\n","Epoch 54/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 2.7727 - val_accuracy: 0.3610\n","Epoch 55/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 2.7916 - val_accuracy: 0.3527\n","Epoch 56/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 2.8323 - val_accuracy: 0.3491\n","Epoch 57/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 2.7700 - val_accuracy: 0.3557\n","Epoch 58/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0358 - accuracy: 0.9874 - val_loss: 2.7967 - val_accuracy: 0.3607\n","Epoch 59/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 2.7711 - val_accuracy: 0.3580\n","Epoch 60/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 2.8607 - val_accuracy: 0.3560\n","Epoch 61/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 2.8065 - val_accuracy: 0.3592\n","Epoch 62/100\n","28/28 [==============================] - 13s 457ms/step - loss: 0.0323 - accuracy: 0.9886 - val_loss: 2.7943 - val_accuracy: 0.3536\n","Epoch 63/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 2.8639 - val_accuracy: 0.3545\n","Epoch 64/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 2.8369 - val_accuracy: 0.3470\n","Epoch 65/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 3.0030 - val_accuracy: 0.3449\n","Epoch 66/100\n","28/28 [==============================] - 13s 466ms/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 2.8959 - val_accuracy: 0.3536\n","Epoch 67/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 2.8117 - val_accuracy: 0.3503\n","Epoch 68/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 2.8321 - val_accuracy: 0.3515\n","Epoch 69/100\n","28/28 [==============================] - 13s 463ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 2.8247 - val_accuracy: 0.3551\n","Epoch 70/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0400 - accuracy: 0.9863 - val_loss: 2.8384 - val_accuracy: 0.3530\n","Epoch 71/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 2.8243 - val_accuracy: 0.3518\n","Epoch 72/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 2.8291 - val_accuracy: 0.3574\n","Epoch 73/100\n","28/28 [==============================] - 13s 466ms/step - loss: 0.0331 - accuracy: 0.9880 - val_loss: 2.8308 - val_accuracy: 0.3512\n","Epoch 74/100\n","28/28 [==============================] - 13s 468ms/step - loss: 0.0366 - accuracy: 0.9868 - val_loss: 2.8798 - val_accuracy: 0.3524\n","Epoch 75/100\n","28/28 [==============================] - 13s 463ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 2.8431 - val_accuracy: 0.3533\n","Epoch 76/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 2.8324 - val_accuracy: 0.3491\n","Epoch 77/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 2.8001 - val_accuracy: 0.3565\n","Epoch 78/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 2.8207 - val_accuracy: 0.3595\n","Epoch 79/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0289 - accuracy: 0.9901 - val_loss: 2.8613 - val_accuracy: 0.3589\n","Epoch 80/100\n","28/28 [==============================] - 13s 470ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 2.8732 - val_accuracy: 0.3405\n","Epoch 81/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0363 - accuracy: 0.9858 - val_loss: 2.8490 - val_accuracy: 0.3497\n","Epoch 82/100\n","28/28 [==============================] - 13s 458ms/step - loss: 0.0408 - accuracy: 0.9850 - val_loss: 2.8904 - val_accuracy: 0.3452\n","Epoch 83/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 2.8522 - val_accuracy: 0.3512\n","Epoch 84/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 2.9141 - val_accuracy: 0.3542\n","Epoch 85/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 2.8705 - val_accuracy: 0.3500\n","Epoch 86/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0374 - accuracy: 0.9865 - val_loss: 2.8377 - val_accuracy: 0.3497\n","Epoch 87/100\n","28/28 [==============================] - 13s 459ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 2.8933 - val_accuracy: 0.3548\n","Epoch 88/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0324 - accuracy: 0.9889 - val_loss: 2.8949 - val_accuracy: 0.3476\n","Epoch 89/100\n","28/28 [==============================] - 13s 463ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 2.8960 - val_accuracy: 0.3426\n","Epoch 90/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0329 - accuracy: 0.9878 - val_loss: 2.8915 - val_accuracy: 0.3491\n","Epoch 91/100\n","28/28 [==============================] - 13s 466ms/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 2.8651 - val_accuracy: 0.3449\n","Epoch 92/100\n","28/28 [==============================] - 13s 463ms/step - loss: 0.0345 - accuracy: 0.9875 - val_loss: 2.8647 - val_accuracy: 0.3524\n","Epoch 93/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 2.8807 - val_accuracy: 0.3432\n","Epoch 94/100\n","28/28 [==============================] - 13s 461ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 2.9075 - val_accuracy: 0.3455\n","Epoch 95/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 2.8932 - val_accuracy: 0.3521\n","Epoch 96/100\n","28/28 [==============================] - 13s 465ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 2.8795 - val_accuracy: 0.3518\n","Epoch 97/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 2.9039 - val_accuracy: 0.3562\n","Epoch 98/100\n","28/28 [==============================] - 13s 460ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 2.8914 - val_accuracy: 0.3336\n","Epoch 99/100\n","28/28 [==============================] - 13s 464ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 2.9069 - val_accuracy: 0.3497\n","Epoch 100/100\n","28/28 [==============================] - 13s 462ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 2.9211 - val_accuracy: 0.3426\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2c1a34cf10>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"tq2A7XMpvYQE"},"source":["**Decoding test**"]},{"cell_type":"code","metadata":{"id":"_zhNXwVfvYQF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623407915511,"user_tz":-270,"elapsed":7063,"user":{"displayName":"محمد باقر فکوری","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ-UCPpVs4BRHzzYHuwttJF-2MdOwIIgB774uy6Q=s64","userId":"02706159974478978394"}},"outputId":"e9011a9c-f78a-42e1-c5d7-389312beb02c"},"source":["pes_vocab = pes_vectorization.get_vocabulary()\n","pes_index_lookup = dict(zip(range(len(pes_vocab)), pes_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","# prediction\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = eng_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = pes_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = pes_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","      \n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","\n","# choice random line text in eng\n","test_eng_texts = [pair[0] for pair in test_persian]\n","for _ in range(30):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequence(input_sentence)\n","    \n","    print(input_sentence)\n","    print(translated)\n","    print(\"\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tom politely pretended not to notice that Mary had been crying.\n","[start] تام کند به قطار آسیب زدند [end]\n","\n","I prefer working to doing nothing.\n","[start] قهوه را ترجیح می‌دهم که کار نکن [end]\n","\n","Are you fond of music?\n","[start] امشب وقتت آزاد است [end]\n","\n","The food is getting cold.\n","[start] غذا حاضر است [end]\n","\n","I never hurt Tom.\n","[start] من هیچ گاه به تام اعتمادی نکردم [end]\n","\n","Lead is easily bent.\n","[start] نبضت عادی است [end]\n","\n","Listen.\n","[start] احتیاط [end]\n","\n","Who?\n","[start] هدف،آتش [end]\n","\n","I got over it. You should, too.\n","[start] من اتاق را با خواهرم شریک هستم [end]\n","\n","We have a wide choice of books.\n","[start] ما بیش از 40 سال است که انجام دهی [end]\n","\n","I've never seen anything like this before.\n","[start] من هیچگاه دوباره شاد نخواهم شد [end]\n","\n","Don't shout.\n","[start] ادامه بده ادامه دادن [end]\n","\n","This bus will take you to the museum.\n","[start] این اتوبوس به دست بعدی می شوم [end]\n","\n","She asked for my help.\n","[start] او از روز اتاق را انجام دهم [end]\n","\n","There's nothing worth watching on TV today.\n","[start] همیشه هیچ چیزی برای خوردن کردن نیست [end]\n","\n","Do you like Japanese food?\n","[start] آیا می دانی چه اتفاقی برای توصیف می کنند [end]\n","\n","I got up at six this morning.\n","[start] تا در حال صبر کردن به نظر نمی رسید [end]\n","\n","A grasshopper and many ants lived in a field.\n","[start] در این پارک پرنده های بسیاری هستند [end]\n","\n","About how many hours will it take to do that?\n","[start] کرایه‌ی تاکسی از اینجا تقریباً چقدر می‌شود [end]\n","\n","When will you leave?\n","[start] کی ترک خواهی کرد [end]\n","\n","I'll bear that in mind.\n","[start] من نمی توانم با در همه صحبت کنم غیر مي آيد [end]\n","\n","We're not accepting any more bids.\n","[start] ما هیچ پیشنهاد دیگری را نمی‌پذیریم [end]\n","\n","I called the police as soon as I saw his dead body on the floor.\n","[start] من در سال 1972 به دنیا آمده ام [end]\n","\n","Can you recommend a hotel near the airport?\n","[start] می‌توانی بروی بیرون، به شرط آنکه قول بدهی [end]\n","\n","I will tell the teacher all about it.\n","[start] من نیاز دارم که با تو دربارهٔ چیزی شخصی صحبت کنم [end]\n","\n","Who?\n","[start] هدف،آتش [end]\n","\n","Tom seems really happy.\n","[start] تام خیلی خوشحال به نظر می‌رسد [end]\n","\n","I think I understand what went wrong.\n","[start] فکر می‌کنم چین نقش فعالی خواهد داشت [end]\n","\n","She baked her husband an apple pie.\n","[start] او به مسئولیت سنگین خود رها شد [end]\n","\n","Tom politely pretended not to notice that Mary had been crying.\n","[start] تام کند به قطار آسیب زدند [end]\n","\n"],"name":"stdout"}]}]}